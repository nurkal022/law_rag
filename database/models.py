from flask_sqlalchemy import SQLAlchemy
from datetime import datetime
import json
import numpy as np
from typing import List, Dict, Optional, Tuple
import os
import glob
from config import Config

# Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ SQLAlchemy
db = SQLAlchemy()

class Document(db.Model):
    """ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°"""
    __tablename__ = 'documents'
    
    id = db.Column(db.Integer, primary_key=True)
    filename = db.Column(db.String(255), unique=True, nullable=False, index=True)
    title = db.Column(db.Text)
    content = db.Column(db.Text, nullable=False)
    file_size = db.Column(db.Integer)
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    updated_at = db.Column(db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    
    # Ð¡Ð²ÑÐ·ÑŒ Ñ Ñ‡Ð°Ð½ÐºÐ°Ð¼Ð¸
    chunks = db.relationship('DocumentChunk', backref='document', lazy='dynamic', cascade='all, delete-orphan')
    
    def to_dict(self):
        return {
            'id': self.id,
            'filename': self.filename,
            'title': self.title,
            'content': self.content,
            'file_size': self.file_size,
            'created_at': self.created_at.isoformat() if self.created_at else None,
            'updated_at': self.updated_at.isoformat() if self.updated_at else None,
            'chunks_count': self.chunks.count()
        }

class DocumentChunk(db.Model):
    """ÐœÐ¾Ð´ÐµÐ»ÑŒ Ñ‡Ð°Ð½ÐºÐ° Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°"""
    __tablename__ = 'document_chunks'
    
    id = db.Column(db.Integer, primary_key=True)
    document_id = db.Column(db.Integer, db.ForeignKey('documents.id'), nullable=False, index=True)
    chunk_index = db.Column(db.Integer, nullable=False)
    content = db.Column(db.Text, nullable=False)
    start_position = db.Column(db.Integer, nullable=False)
    end_position = db.Column(db.Integer, nullable=False)
    chunk_size = db.Column(db.Integer, nullable=False)
    embedding = db.Column(db.LargeBinary)  # Ð”Ð»Ñ Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ numpy array ÐºÐ°Ðº BLOB
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    
    # Ð£Ð½Ð¸ÐºÐ°Ð»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð¿Ð¾ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñƒ Ð¸ Ð¸Ð½Ð´ÐµÐºÑÑƒ Ñ‡Ð°Ð½ÐºÐ°
    __table_args__ = (db.UniqueConstraint('document_id', 'chunk_index'),)
    
    def to_dict(self):
        return {
            'id': self.id,
            'document_id': self.document_id,
            'chunk_index': self.chunk_index,
            'content': self.content,
            'start_position': self.start_position,
            'end_position': self.end_position,
            'chunk_size': self.chunk_size,
            'has_embedding': self.embedding is not None,
            'created_at': self.created_at.isoformat() if self.created_at else None,
            'document_filename': self.document.filename if self.document else None,
            'document_title': self.document.title if self.document else None
        }
    
    def get_embedding(self) -> Optional[np.ndarray]:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ embedding ÐºÐ°Ðº numpy array"""
        if self.embedding:
            return np.frombuffer(self.embedding, dtype=np.float32)
        return None
    
    def set_embedding(self, embedding: np.ndarray):
        """Ð£ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° embedding Ð¸Ð· numpy array"""
        if embedding is not None:
            self.embedding = embedding.astype(np.float32).tobytes()
        else:
            self.embedding = None

class ChatHistory(db.Model):
    """ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ñ‡Ð°Ñ‚Ð°"""
    __tablename__ = 'chat_history'
    
    id = db.Column(db.Integer, primary_key=True)
    session_id = db.Column(db.String(255), nullable=False, index=True)
    user_query = db.Column(db.Text, nullable=False)
    ai_response = db.Column(db.Text, nullable=False)
    sources = db.Column(db.Text)  # JSON Ð¼Ð°ÑÑÐ¸Ð² Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¾Ð²
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    
    def to_dict(self):
        return {
            'id': self.id,
            'session_id': self.session_id,
            'user_query': self.user_query,
            'ai_response': self.ai_response,
            'sources': json.loads(self.sources) if self.sources else [],
            'created_at': self.created_at.isoformat() if self.created_at else None
        }

class LawProject(db.Model):
    """ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð·Ð°ÐºÐ¾Ð½Ð¾Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°"""
    __tablename__ = 'law_projects'
    
    id = db.Column(db.Integer, primary_key=True)
    project_id = db.Column(db.String(255), unique=True, nullable=False, index=True)
    title_ru = db.Column(db.Text, nullable=False)
    title_kz = db.Column(db.Text)
    initiator = db.Column(db.String(255), nullable=False)
    initiator_type = db.Column(db.String(100), nullable=False)
    status = db.Column(db.String(50), default='draft', index=True)
    data_json = db.Column(db.Text)  # JSON Ñ Ð¿Ð¾Ð»Ð½Ñ‹Ð¼Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°
    sections_json = db.Column(db.Text)  # JSON Ñ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ñ€Ð°Ð·Ð´ÐµÐ»Ð°Ð¼Ð¸
    metadata_json = db.Column(db.Text)  # JSON Ñ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸
    generation_date = db.Column(db.DateTime, default=datetime.utcnow)
    last_modified = db.Column(db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    completeness_score = db.Column(db.Float, default=0.0)
    validation_status = db.Column(db.String(50), default='pending')
    
    # Ð¡Ð²ÑÐ·ÑŒ Ñ Ð²ÐµÑ€ÑÐ¸ÑÐ¼Ð¸
    versions = db.relationship('LawProjectVersion', backref='project', lazy='dynamic', cascade='all, delete-orphan')
    
    def to_dict(self):
        return {
            'id': self.id,
            'project_id': self.project_id,
            'title_ru': self.title_ru,
            'title_kz': self.title_kz,
            'initiator': self.initiator,
            'initiator_type': self.initiator_type,
            'status': self.status,
            'data': json.loads(self.data_json) if self.data_json else {},
            'sections': json.loads(self.sections_json) if self.sections_json else {},
            'metadata': json.loads(self.metadata_json) if self.metadata_json else {},
            'generation_date': self.generation_date.isoformat() if self.generation_date else None,
            'last_modified': self.last_modified.isoformat() if self.last_modified else None,
            'completeness_score': self.completeness_score,
            'validation_status': self.validation_status,
            'versions_count': self.versions.count()
        }

class LawProjectVersion(db.Model):
    """ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð²ÐµÑ€ÑÐ¸Ð¸ Ð·Ð°ÐºÐ¾Ð½Ð¾Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° (Ð´Ð»Ñ Ð°ÑƒÐ´Ð¸Ñ‚-Ð»Ð¾Ð³Ð°)"""
    __tablename__ = 'law_project_versions'
    
    id = db.Column(db.Integer, primary_key=True)
    project_id = db.Column(db.String(255), db.ForeignKey('law_projects.project_id'), nullable=False, index=True)
    version = db.Column(db.String(50), nullable=False)
    author = db.Column(db.String(255))
    description = db.Column(db.Text)
    changes_json = db.Column(db.Text)  # JSON Ñ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸ÐµÐ¼ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¹
    sections_json = db.Column(db.Text)  # JSON Ñ Ñ€Ð°Ð·Ð´ÐµÐ»Ð°Ð¼Ð¸ ÑÑ‚Ð¾Ð¹ Ð²ÐµÑ€ÑÐ¸Ð¸
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    
    def to_dict(self):
        return {
            'id': self.id,
            'project_id': self.project_id,
            'version': self.version,
            'author': self.author,
            'description': self.description,
            'changes': json.loads(self.changes_json) if self.changes_json else {},
            'sections': json.loads(self.sections_json) if self.sections_json else {},
            'created_at': self.created_at.isoformat() if self.created_at else None
        }

class LawGenerationSession(db.Model):
    """ÐœÐ¾Ð´ÐµÐ»ÑŒ ÑÐµÑÑÐ¸Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ (Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°Ð½Ð¸Ðµ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ° Ð·Ð°Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ñ)"""
    __tablename__ = 'law_generation_sessions'
    
    id = db.Column(db.Integer, primary_key=True)
    session_id = db.Column(db.String(255), unique=True, nullable=False, index=True)
    project_id = db.Column(db.String(255))
    current_step = db.Column(db.Integer, default=1)
    collected_data = db.Column(db.Text)  # JSON Ñ ÑÐ¾Ð±Ñ€Ð°Ð½Ð½Ñ‹Ð¼Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸
    validation_results = db.Column(db.Text)  # JSON Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°Ð¼Ð¸ Ð²Ð°Ð»Ð¸Ð´Ð°Ñ†Ð¸Ð¸
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    updated_at = db.Column(db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    status = db.Column(db.String(50), default='active')
    
    def to_dict(self):
        return {
            'id': self.id,
            'session_id': self.session_id,
            'project_id': self.project_id,
            'current_step': self.current_step,
            'collected_data': json.loads(self.collected_data) if self.collected_data else {},
            'validation_results': json.loads(self.validation_results) if self.validation_results else {},
            'created_at': self.created_at.isoformat() if self.created_at else None,
            'updated_at': self.updated_at.isoformat() if self.updated_at else None,
            'status': self.status
        }

class DatabaseManager:
    """ÐœÐµÐ½ÐµÐ´Ð¶ÐµÑ€ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ñ SQLAlchemy ORM"""
    
    def __init__(self, app=None):
        self.app = app
        if app is not None:
            self.init_app(app)
    
    def init_app(self, app):
        """Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ Flask Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸ÐµÐ¼"""
        self.app = app
        db.init_app(app)
    
    def ensure_database_exists(self):
        """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð±Ð°Ð·Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ… ÐµÑÐ»Ð¸ ÐµÑ‘ Ð½ÐµÑ‚"""
        if not hasattr(self, '_database_initialized'):
            with self.app.app_context():
                # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ ÐµÑÐ»Ð¸ ÐµÑ‘ Ð½ÐµÑ‚
                os.makedirs(os.path.dirname(Config.DATABASE_PATH), exist_ok=True)
                db.create_all()
                self._database_initialized = True
                # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½ÑƒÐ¶Ð½Ð¾ Ð»Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ¶Ð°Ñ‚ÑŒ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹
                self._auto_populate_if_empty()
    
    def _auto_populate_if_empty(self):
        """ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² ÐµÑÐ»Ð¸ Ð±Ð°Ð·Ð° Ð¿ÑƒÑÑ‚Ð°Ñ"""
        try:
            # ÐŸÑ€ÑÐ¼Ð¾Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ Ð±ÐµÐ· Ð²Ñ‹Ð·Ð¾Ð²Ð° ensure_database_exists
            documents_count = Document.query.count()
            if documents_count == 0:
                print("ðŸ“ Ð‘Ð°Ð·Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð¿ÑƒÑÑ‚Ð°Ñ, Ð½Ð°Ñ‡Ð¸Ð½Ð°ÐµÐ¼ Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÑƒÑŽ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÑƒ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²...")
                self.bulk_load_documents_from_directory('current')
        except Exception as e:
            print(f"ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿Ñ€Ð¾Ð²ÐµÑ€Ð¸Ñ‚ÑŒ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²: {e}")
            # ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ Ð² Ð»ÑŽÐ±Ð¾Ð¼ ÑÐ»ÑƒÑ‡Ð°Ðµ
            self.bulk_load_documents_from_directory('current')
    
    def bulk_load_documents_from_directory(self, directory: str, limit: int = None):
        """ÐœÐ°ÑÑÐ¾Ð²Ð°Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð¸Ð· Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸"""
        if not os.path.exists(directory):
            print(f"âš ï¸  Ð”Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ñ {directory} Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°")
            return {'loaded': 0, 'errors': []}
        
        txt_files = glob.glob(os.path.join(directory, '*.txt'))
        
        if limit:
            txt_files = txt_files[:limit]
        
        if not txt_files:
            print(f"ðŸ“ Ð’ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸Ð¸ {directory} Ð½ÐµÑ‚ .txt Ñ„Ð°Ð¹Ð»Ð¾Ð²")
            return {'loaded': 0, 'errors': []}
        
        print(f"ðŸ“š ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ {len(txt_files)} Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð´Ð»Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸")
        
        loaded = 0
        errors = []
        
        for i, file_path in enumerate(txt_files):
            try:
                filename = os.path.basename(file_path)
                
                # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°
                existing = Document.query.filter_by(filename=filename).first()
                if existing:
                    continue  # Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚ ÑƒÐ¶Ðµ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÐµÑ‚
                
                # Ð§Ð¸Ñ‚Ð°ÐµÐ¼ Ñ„Ð°Ð¹Ð»
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read().strip()
                
                if not content:
                    continue
                
                # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº Ð¸Ð· Ð¸Ð¼ÐµÐ½Ð¸ Ñ„Ð°Ð¹Ð»Ð°
                title = self._extract_title_from_filename(filename)
                
                # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚
                document = Document(
                    filename=filename,
                    title=title,
                    content=content,
                    file_size=len(content)
                )
                
                db.session.add(document)
                loaded += 1
                
                if (i + 1) % 100 == 0:
                    print(f"  ðŸ“„ Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ {i + 1}/{len(txt_files)} Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²...")
                    db.session.commit()  # ÐŸÑ€Ð¾Ð¼ÐµÐ¶ÑƒÑ‚Ð¾Ñ‡Ð½Ñ‹Ð¹ commit
                
            except Exception as e:
                error_msg = f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ {file_path}: {str(e)}"
                errors.append(error_msg)
                print(f"  âŒ {error_msg}")
        
        try:
            db.session.commit()
        except Exception as e:
            db.session.rollback()
            print(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ð¸ Ð² Ð±Ð°Ð·Ñƒ: {e}")
        
        print(f"âœ… Ð—Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð¾ {loaded} Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð² Ð±Ð°Ð·Ñƒ Ð´Ð°Ð½Ð½Ñ‹Ñ…")
        if errors:
            print(f"âš ï¸  ÐžÑˆÐ¸Ð±Ð¾Ðº: {len(errors)}")
        
        return {'loaded': loaded, 'errors': errors}
    
    def _extract_title_from_filename(self, filename: str) -> str:
        """Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ° Ð¸Ð· Ð¸Ð¼ÐµÐ½Ð¸ Ñ„Ð°Ð¹Ð»Ð°"""
        # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸Ðµ Ð¸ Ð·Ð°Ð¼ÐµÐ½ÑÐµÐ¼ ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ‹
        title = os.path.splitext(filename)[0]
        title = title.replace('_', ' ').replace('-', ' ')
        
        # ÐšÐ°Ð¿Ð¸Ñ‚Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ Ð¿ÐµÑ€Ð²ÑƒÑŽ Ð±ÑƒÐºÐ²Ñƒ ÐºÐ°Ð¶Ð´Ð¾Ð³Ð¾ ÑÐ»Ð¾Ð²Ð°
        title = ' '.join(word.capitalize() for word in title.split())
        
        return title[:200]  # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ð´Ð»Ð¸Ð½Ñƒ
    
    def get_unprocessed_documents(self) -> List[Dict]:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð±ÐµÐ· Ñ‡Ð°Ð½ÐºÐ¾Ð²"""
        self.ensure_database_exists()
        
        documents = db.session.query(Document).outerjoin(DocumentChunk).filter(
            DocumentChunk.id.is_(None)
        ).all()
        
        return [doc.to_dict() for doc in documents]
    
    def bulk_insert_chunks(self, chunks_data: List[Dict]):
        """ÐœÐ°ÑÑÐ¾Ð²Ð°Ñ Ð²ÑÑ‚Ð°Ð²ÐºÐ° Ñ‡Ð°Ð½ÐºÐ¾Ð²"""
        try:
            for chunk_data in chunks_data:
                chunk = DocumentChunk(
                    document_id=chunk_data['document_id'],
                    chunk_index=chunk_data['chunk_index'],
                    content=chunk_data['content'],
                    start_position=chunk_data['start_position'],
                    end_position=chunk_data['end_position'],
                    chunk_size=chunk_data['chunk_size']
                )
                
                if 'embedding' in chunk_data and chunk_data['embedding'] is not None:
                    chunk.set_embedding(chunk_data['embedding'])
                
                db.session.add(chunk)
                
                # Commit ÐºÐ°Ð¶Ð´Ñ‹Ðµ 100 Ð·Ð°Ð¿Ð¸ÑÐµÐ¹ Ð´Ð»Ñ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸
                if len(chunks_data) > 100 and (chunks_data.index(chunk_data) + 1) % 100 == 0:
                    db.session.commit()
            
            db.session.commit()
            return True
            
        except Exception as e:
            db.session.rollback()
            print(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¼Ð°ÑÑÐ¾Ð²Ð¾Ð¹ Ð²ÑÑ‚Ð°Ð²ÐºÐ¸ Ñ‡Ð°Ð½ÐºÐ¾Ð²: {e}")
            return False
    
    def insert_document(self, filename: str, content: str, title: str = None) -> int:
        """Ð’ÑÑ‚Ð°Ð²ÐºÐ° Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°"""
        try:
            document = Document(
                filename=filename,
                title=title or self._extract_title_from_filename(filename),
                content=content,
                file_size=len(content)
            )
            
            db.session.add(document)
            db.session.commit()
            
            return document.id
            
        except Exception as e:
            db.session.rollback()
            print(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð²ÑÑ‚Ð°Ð²ÐºÐ¸ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°: {e}")
            return None
    
    def insert_chunk(self, document_id: int, chunk_index: int, content: str, 
                    start_pos: int, end_pos: int, embedding: np.ndarray = None) -> int:
        """Ð’ÑÑ‚Ð°Ð²ÐºÐ° Ñ‡Ð°Ð½ÐºÐ° Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°"""
        try:
            chunk = DocumentChunk(
                document_id=document_id,
                chunk_index=chunk_index,
                content=content,
                start_position=start_pos,
                end_position=end_pos,
                chunk_size=len(content)
            )
            
            if embedding is not None:
                chunk.set_embedding(embedding)
            
            db.session.add(chunk)
            db.session.commit()
            
            return chunk.id
            
        except Exception as e:
            db.session.rollback()
            print(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð²ÑÑ‚Ð°Ð²ÐºÐ¸ Ñ‡Ð°Ð½ÐºÐ°: {e}")
            return None
    
    def get_document_by_filename(self, filename: str) -> Optional[Dict]:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð° Ð¿Ð¾ Ð¸Ð¼ÐµÐ½Ð¸ Ñ„Ð°Ð¹Ð»Ð°"""
        document = Document.query.filter_by(filename=filename).first()
        return document.to_dict() if document else None
    
    def get_all_chunks(self) -> List[Dict]:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð²ÑÐµÑ… Ñ‡Ð°Ð½ÐºÐ¾Ð² Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÐµÐ¹ Ð¾ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ…"""
        chunks = db.session.query(DocumentChunk).join(Document).all()
        return [chunk.to_dict() for chunk in chunks]
    
    def get_all_chunks_with_embeddings(self) -> List[Dict]:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ñ‡Ð°Ð½ÐºÐ¾Ð² Ñ embeddings"""
        chunks = db.session.query(DocumentChunk).filter(
            DocumentChunk.embedding.isnot(None)
        ).join(Document).all()
        
        result = []
        for chunk in chunks:
            chunk_dict = chunk.to_dict()
            chunk_dict['embedding'] = chunk.get_embedding()
            result.append(chunk_dict)
        
        return result
    
    def get_chunk_by_id(self, chunk_id: int) -> Optional[Dict]:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ñ‡Ð°Ð½ÐºÐ° Ð¿Ð¾ ID Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÐµÐ¹ Ð¾ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ðµ"""
        chunk = db.session.query(DocumentChunk).join(Document).filter(
            DocumentChunk.id == chunk_id
        ).first()
        
        return chunk.to_dict() if chunk else None
    
    def save_chat_history(self, session_id: str, user_query: str, 
                         ai_response: str, sources: List[Dict] = None):
        """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ñ‡Ð°Ñ‚Ð°"""
        try:
            chat_entry = ChatHistory(
                session_id=session_id,
                user_query=user_query,
                ai_response=ai_response,
                sources=json.dumps(sources, ensure_ascii=False) if sources else None
            )
            
            db.session.add(chat_entry)
            db.session.commit()
            
        except Exception as e:
            db.session.rollback()
            print(f"ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ñ‡Ð°Ñ‚Ð°: {e}")
    
    def get_chat_history(self, session_id: str, limit: int = 10) -> List[Dict]:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ñ‡Ð°Ñ‚Ð° Ð´Ð»Ñ ÑÐµÑÑÐ¸Ð¸"""
        history = ChatHistory.query.filter_by(session_id=session_id).order_by(
            ChatHistory.created_at.desc()
        ).limit(limit).all()
        
        return [entry.to_dict() for entry in reversed(history)]
    
    def get_documents_stats(self) -> Dict:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ Ð¿Ð¾ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ð¼"""
        self.ensure_database_exists()
        
        documents_count = Document.query.count()
        chunks_count = DocumentChunk.query.count()
        chunks_with_embeddings = DocumentChunk.query.filter(
            DocumentChunk.embedding.isnot(None)
        ).count()
        
        embedding_progress = round(
            (chunks_with_embeddings / chunks_count * 100) if chunks_count > 0 else 0, 1
        )
        
        return {
            'documents_count': documents_count,
            'chunks_count': chunks_count,
            'chunks_with_embeddings': chunks_with_embeddings,
            'embedding_progress': embedding_progress
        }
    
    def save_law_project(self, project_id: str, data_dict: Dict, sections: Dict, metadata: Dict) -> bool:
        """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð·Ð°ÐºÐ¾Ð½Ð¾Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°"""
        try:
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°
            existing = LawProject.query.filter_by(project_id=project_id).first()
            
            if existing:
                # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ð¹
                existing.data_json = json.dumps(data_dict, ensure_ascii=False)
                existing.sections_json = json.dumps(sections, ensure_ascii=False)
                existing.metadata_json = json.dumps(metadata, ensure_ascii=False)
                existing.last_modified = datetime.utcnow()
                existing.title_ru = data_dict.get('title_ru', existing.title_ru)
                existing.title_kz = data_dict.get('title_kz', existing.title_kz)
                existing.initiator = data_dict.get('initiator', existing.initiator)
                existing.initiator_type = data_dict.get('initiator_type', existing.initiator_type)
            else:
                # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð½Ð¾Ð²Ñ‹Ð¹
                project = LawProject(
                    project_id=project_id,
                    title_ru=data_dict.get('title_ru', 'Ð‘ÐµÐ· Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ'),
                    title_kz=data_dict.get('title_kz'),
                    initiator=data_dict.get('initiator', 'ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾'),
                    initiator_type=data_dict.get('initiator_type', 'other'),
                    data_json=json.dumps(data_dict, ensure_ascii=False),
                    sections_json=json.dumps(sections, ensure_ascii=False),
                    metadata_json=json.dumps(metadata, ensure_ascii=False)
                )
                db.session.add(project)
            
            db.session.commit()
            return True
            
        except Exception as e:
            db.session.rollback()
            print(f"ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ð·Ð°ÐºÐ¾Ð½Ð¾Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°: {e}")
            return False
    
    def get_law_project(self, project_id: str) -> Optional[Dict]:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð·Ð°ÐºÐ¾Ð½Ð¾Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° Ð¿Ð¾ ID"""
        project = LawProject.query.filter_by(project_id=project_id).first()
        return project.to_dict() if project else None
    
    def get_law_projects_list(self, status: str = None, limit: int = 50) -> List[Dict]:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÐ¿Ð¸ÑÐºÐ° Ð·Ð°ÐºÐ¾Ð½Ð¾Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð¾Ð²"""
        query = LawProject.query
        
        if status:
            query = query.filter_by(status=status)
        
        projects = query.order_by(LawProject.generation_date.desc()).limit(limit).all()
        return [project.to_dict() for project in projects]
    
    def save_generation_session(self, session_id: str, current_step: int = 1, 
                              collected_data: Dict = None, validation_results: Dict = None) -> bool:
        """Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ ÑÐµÑÑÐ¸Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸"""
        try:
            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²Ð¾Ð²Ð°Ð½Ð¸Ðµ ÑÐµÑÑÐ¸Ð¸
            existing = LawGenerationSession.query.filter_by(session_id=session_id).first()
            
            if existing:
                # ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÑƒÑŽ
                existing.current_step = current_step
                if collected_data:
                    existing.collected_data = json.dumps(collected_data, ensure_ascii=False)
                if validation_results:
                    existing.validation_results = json.dumps(validation_results, ensure_ascii=False)
                existing.updated_at = datetime.utcnow()
            else:
                # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð½Ð¾Ð²ÑƒÑŽ
                session = LawGenerationSession(
                    session_id=session_id,
                    current_step=current_step,
                    collected_data=json.dumps(collected_data, ensure_ascii=False) if collected_data else None,
                    validation_results=json.dumps(validation_results, ensure_ascii=False) if validation_results else None
                )
                db.session.add(session)
            
            db.session.commit()
            return True
            
        except Exception as e:
            db.session.rollback()
            print(f"ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ ÑÐµÑÑÐ¸Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸: {e}")
            return False
    
    def get_generation_session(self, session_id: str) -> Optional[Dict]:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÐµÑÑÐ¸Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸"""
        session = LawGenerationSession.query.filter_by(session_id=session_id).first()
        return session.to_dict() if session else None
    
    def get_law_projects_stats(self) -> Dict:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ¸ Ð¿Ð¾ Ð·Ð°ÐºÐ¾Ð½Ð¾Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð°Ð¼"""
        total_projects = LawProject.query.count()
        recent_projects = LawProject.query.filter(
            LawProject.generation_date >= datetime.utcnow().replace(day=1)
        ).count()
        
        return {
            'total_projects': total_projects,
            'recent_projects': recent_projects
        } 