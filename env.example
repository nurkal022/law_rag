# ============================================================================
# Пример конфигурации для LawRAG
# Скопируйте этот файл как .env и заполните значения
# ============================================================================

# LLM Provider Configuration
# Тип провайдера: 'openai' (облачный) или 'ollama' (локальный)
LLM_PROVIDER_TYPE=openai

# Модель по умолчанию
# Для OpenAI: gpt-4o, gpt-4-turbo, gpt-4, gpt-3.5-turbo
# Для Ollama: llama3.2, llama3.1, mistral, qwen2.5, phi3 и др.
LLM_MODEL=gpt-4o

# OpenAI API Configuration
# Получите ключ на https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Ollama Configuration (только для LLM_PROVIDER_TYPE=ollama)
# URL вашего локального Ollama сервера
OLLAMA_BASE_URL=http://localhost:11434

# Flask Configuration
SECRET_KEY=your_secret_key_here_change_this_in_production
DEBUG=True

# Application Settings
APP_HOST=0.0.0.0
APP_PORT=5001

# Database Configuration
DATABASE_PATH=database/law_database.db

# Document Processing
DOCUMENTS_DIR=current
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# RAG Settings
MAX_TOKENS=4000
TEMPERATURE=0.1
TOP_K_RESULTS=5

# Embedding Model
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
EMBEDDING_MODEL_OFFLINE=all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# Logging
LOG_LEVEL=INFO
LOG_FILE=app.log

# Security (for production)
# HTTPS_ONLY=True
# SESSION_COOKIE_SECURE=True
# SESSION_COOKIE_HTTPONLY=True

# Performance
# WORKERS=4
# THREADS=2
# MAX_CONTENT_LENGTH=16777216  # 16MB

# Cache Settings
# CACHE_TYPE=simple
# CACHE_DEFAULT_TIMEOUT=300

# Rate Limiting (requests per minute)
# RATE_LIMIT_STORAGE_URL=memory://
# RATE_LIMIT_DEFAULT=100 